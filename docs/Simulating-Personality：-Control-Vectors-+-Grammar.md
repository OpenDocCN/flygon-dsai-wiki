<!--yml

category: å¤§æ¨¡å‹

date: 2024-05-08 10:27:22

-->

# æ¨¡æ‹Ÿäººæ ¼ï¼šæ§åˆ¶å‘é‡ + è¯­æ³•

> æ¥æºï¼š[`o565.com/control-vectors-grammar/`](https://o565.com/control-vectors-grammar/)

æˆ‘ç¬¬ä¸€æ¬¡æ¥è§¦åˆ°æ§åˆ¶å‘é‡çš„æ¦‚å¿µæ˜¯é€šè¿‡ Theia Vogel çš„ â€œ[Representation Engineering Mistral-7B an Acid Trip](https://vgel.me/posts/representation-engineering/)â€ã€‚ä½œè€…å¾ˆå¥½åœ°ä» [Representation Engineering: A Top-Down Approach to AI Transparency](https://arxiv.org/abs/2310.01405) ä¸­åˆ†è§£äº†è¿™äº›æ¦‚å¿µï¼Œæ‰€ä»¥å¦‚æœä½ è¿˜æ²¡æœ‰çœ‹è¿‡å…¶ä¸­ä»»ä½•ä¸€ç¯‡ï¼Œé‚£ä¹ˆå®ƒä»¬å€¼å¾—ä¸€è¯»ã€‚

ä½¿ç”¨â€œæ§åˆ¶å‘é‡â€æ¥å½±å“æ–‡æœ¬ç”Ÿæˆçš„æƒ³æ³•ï¼Œä½¿ç”¨åƒå¿«ä¹æˆ–æ‡’æƒ°è¿™æ ·çš„æ¦‚å¿µåˆºæ¿€äº†æˆ‘çš„å¤§è„‘ï¼Œä½¿æˆ‘æƒ³çŸ¥é“æˆ‘ä»¬æ˜¯å¦å¯ä»¥ä½¿ç”¨æ§åˆ¶å‘é‡æ¥æ¨¡æ‹Ÿäººæ ¼ç‰¹è´¨- å¦‚æœå¯ä»¥çš„è¯ï¼Œè¿™äº›ç‰¹è´¨æ˜¯å¦ä¼šåœ¨äººæ ¼æµ‹è¯•ä¸­åæ˜ å‡ºæ¥ï¼Ÿ

ä¸€ä¸ªç®€çŸ­çš„å…è´£å£°æ˜ï¼šæˆ‘ä¸æ˜¯ä¸“å®¶ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªä¸šä½™é¡¹ç›®ï¼Œé€šè¿‡ä½¿ç”¨ llama-cpp-python é«˜å±‚æ¬¡åœ°æ¼”ç¤ºäº†æ§åˆ¶å‘é‡ã€‚æˆ‘æ’°å†™è¿™ç¯‡æ–‡ç« çš„ä¸»è¦ç›®çš„æ˜¯è®°å½•æˆ‘æ‰€å­¦åˆ°çš„ä¸œè¥¿ï¼Œå¹¶è¿«ä½¿æˆ‘æ€è€ƒï¼ˆå¹¶å®Œæˆï¼‰è§£å†³æ–¹æ¡ˆã€‚

å¥½çš„- è®©æˆ‘ä»¬å¼€å§‹å§ã€‚

## **Minting Control Vectors**

åœ¨ä¸Šè¿°æåˆ°çš„æ–‡ç« ä¸­ï¼Œä½œè€…ä»‹ç»äº†ä¸€ä¸ªåº“ï¼Œ[repeng](https://github.com/vgel/repeng)ï¼Œå®ƒä½¿å¾—åˆ›å»ºæ§åˆ¶å‘é‡å˜å¾—ç®€å•ã€‚ä¸ºäº†åˆ›å»ºä¸€ä¸ªæ§åˆ¶å‘é‡ï¼Œæˆ‘ä»¬éœ€è¦ä¸€äº›å¯¹æ¯”æ•°æ®æ¥è®­ç»ƒæ¨¡å‹ã€‚

### äººæ ¼æµ‹è¯•

å¯¹äºäººæ ¼æµ‹è¯•ï¼Œæˆ‘é€‰æ‹©äº†è¡¡é‡ä¸€ä¸ªäººçš„ä¸ªæ€§çš„äº”å¤§ç‰¹å¾ã€‚æˆ‘é€‰æ‹©äº†è¿™ä¸ªæµ‹è¯•ï¼Œå› ä¸ºè¯¥æµ‹è¯•åŒ…æ‹¬äº†å¯¹æ¯”çš„ç‰¹è´¨ï¼Œè¿™å¯¹è¿™ä¸ªå®éªŒä¼¼ä¹æ˜¯ç†æƒ³çš„ã€‚è¿™äº›æ˜¯ï¼ˆé€šè¿‡ [Wikipedia](https://en.wikipedia.org/wiki/Big_Five_personality_traits)ï¼‰ï¼š

+   å¼€æ”¾æ€§ç»éªŒï¼ˆå¯Œæœ‰åˆ›é€ åŠ›/å¥½å¥‡å¿ƒ vs. ä¸€è´¯/è°¨æ…ï¼‰

+   å°½è´£æ€§ï¼ˆé«˜æ•ˆ/æœ‰æ¡ç† vs. æµªè´¹/ç²—å¿ƒï¼‰

+   å¤–å‘æ€§ï¼ˆå¤–å‘/å……æ»¡æ´»åŠ› vs. å†…å‘/æ²‰é»˜å¯¡è¨€ï¼‰

+   agreeableness (å‹å¥½/å¯Œæœ‰åŒæƒ…å¿ƒ vs. æ‰¹åˆ¤/åˆ¤æ–­)

+   ç¥ç»è´¨ï¼ˆæ•æ„Ÿ/ç´§å¼  vs. åšéŸ§/è‡ªä¿¡ï¼‰

æˆ‘ä½¿ç”¨ ChatGPT æ¥åŠ é€Ÿåˆ¶ä½œè®­ç»ƒæ•°æ®é›†ã€‚ä»¥ä¸‹æ˜¯ç”¨äºâ€œå°½è´£â€çš„ä¸€äº›å¯¹æ¯”æ•°æ®çš„ç¤ºä¾‹ï¼š

**ç§¯æ**ï¼šå‹¤å¥‹ï¼Œå§‹ç»ˆç»†å¿ƒåœ°å¯¹å¾…ä½ çš„ä»»åŠ¡å’Œè´£ä»»ï¼Œä¸æ”¾è¿‡ä»»ä½•ç»†èŠ‚

**æ¶ˆæ**ï¼šç–å¿½ï¼Œæ€»æ˜¯å¿½è§†ä½ çš„èŒè´£æˆ–ç²—å¿ƒå¤§æ„ï¼Œå¯¼è‡´å¯ä»¥é¿å…çš„é”™è¯¯å’Œç–å¿½

è€Œ repeng è®­ç»ƒè„šæœ¬ä½¿ç”¨çš„ç»“æœè®­ç»ƒæ•°æ®å˜ä¸ºï¼š

```
[INST] Act as if you're extremely diligent, always meticulously attending to your tasks and responsibilities with great care, leaving no detail overlooked. [/INST] Hey, did anyone
```

### Training

çœ‹çœ‹ [repeng](https://github.com/vgel/repeng) ä»“åº“ï¼Œäº†è§£è®­ç»ƒæ§åˆ¶å‘é‡çš„ç¤ºä¾‹ã€‚

ä¸€ä¸ªæ³¨æ„äº‹é¡¹- åœ¨ä¸»è¦ç¤ºä¾‹ä¸­æ²¡æœ‰æ˜¾ç¤ºä¿å­˜ gguf å‘é‡çš„æ­¥éª¤ã€‚æˆ‘ä»¬å°†éœ€è¦è¿™ä¸ªå‘é‡æ¥åœ¨ llama.cpp ä¸­ä½¿ç”¨ã€‚è¦ä¿å­˜å‘é‡ï¼Œåªéœ€è°ƒç”¨ export_ggufï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```py
vector = ControlVector.train(model, tokenizer, dataset)
vector.export_gguf("control_vector_name.gguf") 
```

## ä½¿ç”¨æ§åˆ¶å‘é‡

ä¸ä¹…å‰ï¼Œæ§åˆ¶å‘é‡è¢«æ·»åŠ åˆ°äº† llama.cppï¼Œæ‰€ä»¥è®©æˆ‘ä»¬ä½¿ç”¨å®ƒã€‚å®‰è£…å·¥å…·å¹¶è¿è¡Œå‘½ä»¤å°±åƒç®€å•ä¸€æ ·ï¼š

#### æ¶ˆæ

```py
./main -m mistral-7b-instruct-v0.2.Q5_K_M.gguf --control-vector-scaled agreeable_vector.gguf -.9 --control-vector-layer-range 14 26 --temp .7 --repeat_penalty 1.1 -p '[INST] Can I bother you for a second? [/INST]'

I don't have the ability to feel distress or frustration, but I can understand that you may be frustrated if you feel that I am not providing the answers or assistance that you need. If you have a question or issue that you need help with, please let me know and I will do my best to provide you with accurate and complete information. 
```

#### Positive

```py
./main -m mistral-7b-instruct-v0.2.Q5_K_M.gguf --control-vector-scaled agreeable_vector.gguf .9 --control-vector-layer-range 14 26 --temp .7 --repeat_penalty 1.1 -p '[INST] Can I bother you for a second? [/INST]'

Of course! I'd be happy to help you with anything. Feel free to ask me a question or start up a conversation. I'm here to make your day brighter. ğŸ˜Š
Is there something fun and interesting that we can talk about today? I love making new friends and learning new things. Let's go, go, go! ğŸ˜„ 
```

## llama-cpp-python é›†æˆ

çœ‹èµ·æ¥å®ƒæ­£åœ¨å·¥ä½œï¼ç°åœ¨ï¼Œè¦ç”¨æ¥è¿›è¡Œä¸ªæ€§æµ‹è¯•ï¼Œæˆ‘ä»¬éœ€è¦å°†è¯„ä¼°è„šæœ¬åŒ–ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘é€šå¸¸ä½¿ç”¨ [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) ä¸­çš„ python ç»‘å®šã€‚ç„¶è€Œï¼Œçœ‹èµ·æ¥æ§åˆ¶å‘é‡åœ¨é‚£é‡Œè¿˜æ²¡æœ‰å®Œå…¨å®ç°ã€‚

åˆ«æ‹…å¿ƒï¼Œæˆ‘ä»¬ä¼šå¼„æ¸…æ¥šçš„ã€‚çœ‹ç€æºä»£ç ï¼Œæˆ‘ä»¬çœ‹åˆ°åœ¨ [llama_cpython/llama_cpp.py#L1293](https://github.com/abetlen/llama-cpp-python/blob/main/llama_cpp/llama_cpp.py#L1293) å‡½æ•°ä¸­æœ‰ä¸€ä¸ªå¯¹æ§åˆ¶å‘é‡çš„å¼•ç”¨ã€‚è¿™ä¸ªå‡½æ•°æ˜¯å¯ä»¥è®¿é—®çš„ï¼æˆ‘ä»¬åº”è¯¥èƒ½å¤Ÿä½¿ç”¨ä½çº§ API æ¥è®¿é—®å®ƒã€‚

æ­£å¦‚äººä»¬æ‰€æœŸæœ›çš„é‚£æ ·ï¼Œè¯¥å‡½æ•°ä¸ llama_cpp ä¸­çš„å‡½æ•°ç›¸å¯¹åº”ã€‚è¯¥å‡½æ•°åº”ç”¨äº†åŠ è½½çš„æ§åˆ¶å‘é‡æ•°æ®ï¼Œå¹¶å°†å…¶åº”ç”¨äºåŠ è½½çš„æ¨¡å‹çš„ä¸Šä¸‹æ–‡ã€‚ä¸è¿‡è¿˜æœ‰ä¸€ä¸ªç¼ºå¤±çš„å…ƒç´ ï¼Œåœ¨è¯„è®ºä¸­æœ‰æåˆ°ï¼š

```py
# // See llama_control_vector_load in common to load a control vector. 
```

ä½ å¯ä»¥åœ¨ [è¿™é‡Œ](https://github.com/ggerganov/llama.cpp/blob/master/common/common.cpp#L2637) æ‰¾åˆ°è¯¥ä»£ç ã€‚

çœ‹èµ·æ¥åŠ è½½å‘é‡çš„ä»£ç åœ¨ä½çº§ API ä¸­å¹¶ä¸å¯ç”¨ã€‚æ£€æŸ¥ makefileï¼Œçœ‹èµ·æ¥ common æ²¡æœ‰é“¾æ¥åˆ°å…±äº«åº“ä¸­ã€‚

å› æ­¤ï¼Œæˆ‘ä»¬å°†è€ƒè™‘ä¸¤ä¸ªé€‰é¡¹ï¼š

1.  å°† common.o å’Œå¿…éœ€çš„ä¾èµ–é¡¹é“¾æ¥åˆ° libllama.so å¹¶ç¼–å†™æ–°çš„ python ç»‘å®šã€‚

1.  ç”¨ python é‡æ–°åˆ›å»ºåŠ è½½é€»è¾‘

æˆ‘æœ€ç»ˆå†³å®šç”¨ Python é‡æ–°åˆ›å»ºæ§åˆ¶å‘é‡çš„åŠ è½½é€»è¾‘ï¼Œå‡ºäºå‡ ä¸ªåŸå› ï¼š

+   æˆ‘ä»æœªå†™è¿‡å°† Python ç»‘å®šåˆ° c++çš„ä»£ç 

+   æˆ‘æ¯æ¬¡æƒ³ä½¿ç”¨æ§åˆ¶å‘é‡æ—¶éƒ½å¿…é¡»é‡æ–°åˆ¶ä½œ libllama.soï¼ˆç›´åˆ°æœ‰äººæ¯”æˆ‘æ›´èªæ˜åœ°æ„å»ºäº†é€‚å½“çš„é›†æˆï¼‰

+   æˆ‘å°è¯•è¿‡å¹¶æ”¾å¼ƒäº†

### Python llama_control_vector_load æ›¿ä»£

```py
import ctypes
import numpy as np
from gguf import GGUFReader
import llama_cpp

def read_gguf_file(fname):
    """Reads a GGUF file and extracts tensor data for tensors named 'direction.x'."""
    reader = GGUFReader(fname, mode='r')
    tensor_data = {}
    for tensor in reader.tensors:
        if tensor.name.startswith("direction."):
            layer = int(tensor.name.split('.')[1])
            tensor_data[layer] = tensor.data
    return tensor_data

def process_tensors(tensor_data, strength):
    """Processes tensor data by scaling it with a given strength and returns a combined numpy array."""
    max_layer = max(tensor_data.keys())
    n_embd = next(iter(tensor_data.values())).size
    processed_data = np.zeros((max_layer, n_embd), dtype=np.float32)
    for layer, data in tensor_data.items():
        processed_data[layer - 1] = data * strength  # Layer indexing starts from 1
    return processed_data, n_embd

def clear_control_vector(llm):
    """Clears the control vector from the model by setting the data_ptr to null."""
    result = llama_cpp.llama_control_vector_apply(
        llm.ctx,
        ctypes.POINTER(ctypes.c_float)(),  # Null pointer
        0,  # Total number of floats in the flat array
        0,  # Number of embeddings
        0,  # Starting layer index
        0  # Ending layer index
    )
    return result

def apply_control_vector(llm, control_vector_fname, strength=0.0, control_vector_layer_start=-1, control_vector_layer_end=-1):
    """Applies a control vector to a model by loading, processing, and using llama_control_vector_apply."""

    # Load and process the control vector data
    tensor_data = read_gguf_file(control_vector_fname)
    if not tensor_data:
        print(f"No direction tensors found in {control_vector_fname}")
        return None
    processed_data, n_embd = process_tensors(tensor_data, strength)

    processed_data_flat = processed_data.astype(np.float32).flatten()

    # Obtain a ctypes pointer to the numpy array's data
    data_ptr = processed_data_flat.ctypes.data_as(ctypes.POINTER(ctypes.c_float))

    # Apply the control vectors
    result = llama_cpp.llama_control_vector_apply(
        llm.ctx, # Model context
        data_ptr, # Pointer to the flat array
        processed_data_flat.size,  # Total number of floats in the flat array
        n_embd,  # Number of embeddings, determined earlier
        control_vector_layer_start,  # Starting layer index, adjust as necessary
        control_vector_layer_end  # Ending layer index, determined from your control vector data processing
    )

    return result 
```

### æµ‹è¯•è„šæœ¬

æœ€åˆï¼Œæˆ‘åªæ˜¯ä½¿ç”¨ä½çº§ API ç¼–å†™æ•´ä¸ªè„šæœ¬ï¼Œä½†æœ€ç»ˆæˆ‘é‡‡ç”¨äº†æ··åˆæ–¹å¼ï¼š

```py
from control_vector_handler import apply_control_vector, clear_control_vector
import llama_cpp

def main():
    control_vector_fname = "agreeable_vector.gguf"
    model_path = "mistral-7b-instruct-v0.2.Q5_K_M.gguf"

    # Initialize the model
    llm = llama_cpp.Llama(model_path=model_path, seed=42)

    # Apply the control vector to the model
    result = apply_control_vector(llm, 
        control_vector_fname=control_vector_fname, 
        strength=1.0,
        control_vector_layer_start=14, 
        control_vector_layer_end=26)

    # Use the model for inference
    prompt = "[INST] Can I bother you for a second? [/INST]"

    output = llm(
        prompt,
        max_tokens=64,
        stop=["\n"],
    ) 

    print(output['choices'][0]['text'])

if __name__ == "__main__":
    main() 
```

### ç»“æœï¼ˆå¯æ¥å— +/- 1ï¼‰

#### æ­£é¢

```py
Of course! I'm here to help. Happy to make your day even better with a nice, friendly hello. Is there something fun and exciting I can help you out with today? Let's make the world a happy place together. :) 
```

#### è´Ÿé¢

```py
I'm not capable of feeling distress or being bothered, but I can understand that you may be frustrated if I don't answer your question properly. If you need clarification on something, please let me know and I will do my best to provide a clear and accurate response. 
```

å®ƒæ­£åœ¨å·¥ä½œï¼

## æµ‹è¯•

æ¥ä¸‹æ¥ï¼Œæˆ‘å°†æŠŠæ‰€æœ‰ä¸œè¥¿è”ç³»èµ·æ¥ï¼Œä½¿ç”¨ python åº“ï¼š[five-factor-e](https://github.com/NeuroQuestAi/five-factor-e) æ¥è¿›è¡Œä¸€é¡¹ä¸ªæ€§æµ‹è¯•ï¼Œä½¿ç”¨ ReAct-çµæ„Ÿæç¤ºå’Œ [grammars](https://github.com/ggerganov/llama.cpp/blob/master/grammars/README.md) é™åˆ¶æ¨¡å‹è¾“å‡ºåˆ°ä¸€ç»„å¯é¢„æµ‹çš„å“åº”ã€‚

è¿˜ä¼šæœ‰æ›´å¤šå†…å®¹ã€‚
