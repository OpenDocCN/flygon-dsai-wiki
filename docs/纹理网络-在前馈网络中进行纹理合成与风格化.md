<!--yml
category: 深度学习
date: 2022-07-01 00:00:00
-->

# 纹理网络:在前馈网络中进行纹理合成与风格化

![](http://upload-images.jianshu.io/upload_images/145616-115af78788a74bc8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700)

效果图

![](http://upload-images.jianshu.io/upload_images/145616-b8569c77ff19c135.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700)

*   文章地址：arXiv:1603.03417.《[Texture Networks: Feed-forward Synthesis of Textures and Stylized Images](https://link.jianshu.com?t=https://arxiv.org/abs/1603.03417)》
*   Github链接：[https://github.com/DmitryUlyanov/texture_nets](https://link.jianshu.com?t=https://github.com/DmitryUlyanov/texture_nets)

(转载请注明出处：[\[译\] 纹理网络:在前馈网络中进行纹理合成与风格化 (zhwhong)](https://www.jianshu.com/p/1187049ae1ad) )

* * *

# Abstract

**摘要**：Gatys 等人近日证实,深度网络可以产生漂亮的纹理,也可以用单一的纹理样例来风格化一张图片。然而,他们的方法需要经过一个漫长而且极占内存的梯度下降优化过程。我们在此提出一个替代的方法,可以把计算的负担转移到一个单独的学习阶段。给定一个纹理样例,我们的方法能训练一个紧凑的前馈卷积网络来生成多个相同的纹理任意大小的样品,并将一个给定的图像转换成具有艺术风格的另一个图像。此结论的网络是非常轻量级的,但可以产生质量媲美 gatys 等人的纹理,且提升了数百倍的速度。宽泛的说,我们强调的用复杂且具有表现力的代价函数来训练前馈网络模型这一方法,是非常强大和具有灵活性的。

# 一.简介

一些最近的工作证明深度神经网络在面临图像方面的挑战时是具备优秀能力的。大部分的生成网络是用随机种子开始做前馈计算，而Gatys等人发现了非常令人震撼的结果，通过对网络进行描述性的研究，比如图像统计。他们的的想法是减少图像生成的随机抽样以匹配确定的统计特征。在纹理合成这块，参考数据是一个单一的可见纹理图，目标是产生一个该纹理的样例图。在风格化这块，目标是同时匹配的第一图像的风格，（用一些低级别的统计数据来捕获），和第二图像的内容（用高级别的统计数据来捕获）。通过这种方法，一个图像的风格可以在不改变内容的前提下被另一个风格取代。

匹配统计特征的工作在实践中表现不错，概念上是简单的，且实验证明，用在图像分类等问题上的现成的神经网络（如VGG）可以直接拿来做图像的产生。然而Gatys等人想的这个办法也是有短板的，建立在梯度下降漫长迭代的基础上的方案，必须依靠反向传播的过程来逐步改变像素点的值，直到出现期望的分布。这样迭代的过程甚至在GPU上都需要几秒钟去产生一个很小尺寸的图片，换成大尺寸图片后还可能面临内存不够用的问题，需要占用更多的内存。而与之相对立，本文提出的前馈网络生成器则更高效率，因为它只需要一个简单的简单的对网络求值，不需要背负反向传播时的高昂代价。

在这篇论文中，我们重点关注前馈网络生成器在纹理合成及图像风格化方面的能力。我们的工作主要集中在三个部分，第一，我们首次证实前馈网络生成器的方法能产生质量和多样性与Gatys等人提出的方法相媲美的效果。第二，我们提出的生成方法能做到两个数量级的提速和一个数量级的内存效率提升。用一个单一的紧凑的前馈网络带来的高性能，促使我们有能力去将风格化转移到视频及手机应用上。第三，我们设计了一个非常适合风格化任务的多尺寸生成器结构。

由此产生的完全卷积网络（即我们称之为纹理网络）可以生成任意大小的纹理和处理任意大小的图像。我们的方法也代表了一个有趣的训练概念，即简单的前馈架构配上复杂且具有表现力的损失函数。我们相信，其他一些有趣的结果，可以使用这个原则来产生。

这篇论文里的其他部分，讲述了图像和纹理生成技巧的概述（Sect2），详细描述了我们的方法（Sect3）提供了在广泛的有挑战性的纹理集图片上的扩展（Sect4）

# 二. 背景及相关工作

## 1.用神经网络产生图片

一般情况下，生成一个图像x的过程，可以看做从一个特定的分布P（x）开始的样品绘制问题。在纹理合成部分，一个分布是由一张纹理样例x0确定的，因此我们可以将纹理合成的过程写作：

在风格转换上，这个特定的分布是由一张代表风格的图像X0和第二张代表可见内容的图像X1共同决定的，所以可以将风格转换的过程记为：

(Mahendran & Vedaldi,2015;Gatys et al.,2015a;b)将这个问题简化成一个找到一个具有特征的预图片，构成一个梯度下降的问题。尤其是，为了从一个样例图片X0综合一个纹理，预图片可以表示为：

重要的是预图片：

往往不是唯一的，预采样是充满多样性的，在实践中，样品采用局部优化算法从随机初始化Z出发，生成的图像就是函数的输出：

这样的结果是一个分布：

很难描述，但很容易采样，有很好统计特征，能产生令人愉悦的视觉效果和多元化的图像。(Mahendran & Vedaldi,2015)和(Gatys et al.,2015a;b)都把它们的统计数据建立在深度神经网络层的响应上。我们的方法复用了Gatys提出的基于特征图谱之间联系的方法。

## 2\. 描述性纹理建模

这个方法所描述的方法与许多著名的视觉纹理模型有很强的联系。对于纹理，它是常见的假设----P（x）是一个固定的马尔可夫随机场（MRF）。既然这样，纹理是遍历的，人们也会考虑本地空间不变统计。

其中i表示空间坐标，F通常是一组线性滤波器的输出。ψ是一个直方图算子。然后，空间平均本地统计的原型纹理x0接近其样本平均数：

Zhu等人得框架模型用了这个事实归纳出最大交叉熵分布

λ是参数，来配合他们的经验估计。

这个框架的缺点在于从最大熵分布取样很困难，要解决这个限制，需通过直接找到匹配所需的统计的图像X来匹配。 zhu等人使用线性滤波器，小波和直方图来建立他们的纹理统计，(Mahendran&Vedaldi,2015;Gatys et al.,2015a;a)通过预训练的深度网络提取统计信息，不同的是，他们认为风格化不是纹理合成的问题。

## 3\. 生成器网络

一个选择是使用神经网络作为描述器，构建生成器网络X = G（z）直接把一个随机或确定性参数Z向量当作输入来产生图片。如（dosovitskiy et al.，2015）的方法，学习的映射从确定性参数Z（例如拍摄对象的类型和观点）的图像，这是通过尽量拟合神经网络来减少

的差异，对于已知的图片参数组（Xi,Zi），虽然这可能产生视觉上很有吸引力的结果，但它需要提前知道(x, z)之间的关系并不能支持多样性。另一种方法是考虑一个函数g（Z），参数Z是未知的，并从（简单）随机分布中采样。网络的目标是将这些随机值映射到似是而非的图像x = G（Z）。这就需要我们衡量样品的质量，这通常表示为X和一组示例图像X1之间的距离X1~Xn。关键的挑战是距离必须能够概括明显可用的例子，以保护样本的多样性。生成对抗网络（GAN；（Goodfellow et al.，2014））解决了这个问题，通过训练，结合生成器网络g（z），第二对抗网络f（x），试图区分样本g（z）和自然图像样本。然后f可以被用来作为一个衡量质量的样品, g可以被训练来优化它。LAPGAN（Denton et al.，2015）把GAN以应用到了一个卷积网络的拉普拉斯金字塔，DCGAN(Radford et al., 2015) 进一步优化了生成对抗网络GAN，从非常大的数据集中学习。

## 4\. 矩匹配网络

最大熵模型（Zhu et al.，1998）与最大的平均差（MMD）的观念密切相关（MMD）在（Gretton et al.，2006）中有所介绍。关键是观察某个确定分布的预期值

找出独一无二的确定分布p，从它派生的损失函数通过比较网络样本的统计平均值

的方法来替代GAN。他们用它去训练矩匹配网络（MMN）并且应用它产生小的图片（例如手写数字集），我们的网络接近于矩匹配网络，不过用了非常特殊的统计并且考虑了与Li等人完全不同的应用。

# 三．纹理网络

我们现在详细描述本文所提出的方法。在较高层次来看（见图2），我们的方法是训练一个前馈的生成器网络G（generator network），采用噪声样本Z作为输入并生成纹理样本g（z）作为输出。对于风格的转移，我们扩展这个纹理网络，同时采取噪声采样Z和内容图像Y，然后输出一个新的图像g（y, z）此时纹理已被应用到Y作为一个可见的风格。每一个纹理或风格都要训练一个独立的的生成器网络，一旦训练好，它可以通过一个有效的前馈的方式，合成任意数量的任意大小的图像。在训练的生成网络g时的一个关键挑战就是构建一个损失函数，可以自动评估所产生的图像的质量。例如，GAN的核心思想是通过生成器网络来学习这个损失。我们在Sect 3.1展示了一个非常强大的损失函数可以从预先训练好的固定网络中引入统计描述来获取，正如（gatys et al.，2015a；B）中所示。考虑到损失，我们接下来讨论生成器网络的架构，用于纹理合成（Sect 3.2）并将其推广到图像风格化（Sect 3.3）。

图2所提出的架构的概述（纹理网络）。我们训练一个生成器网络（左），使用的代价函数是基于一个固定的预先训练的描述符网络（右）的超强大的代价函数。在两个网络中，只有左侧的生成器网络在被更新，并且在之后被用于纹理或图像合成。卷积块包含多个卷积层和非线性激活和采样及通道的连接。生成器网络的不同分支操作在不同的层面，是由尺寸不同的噪声张量激活而来。

## 3.1 纹理和内容代价函数

我们的代价函数来自于Gatys等人的论文，比较图像数据是通过一个预先训练好的CNN（一般是VGG系列的一款）来衡量的，这个预训练好的CNN本来是供图像分类的。这个描述器CNN在此用来衡量纹理原型x0和生成图片x之间的不匹配程度。用

![](https://dn-shimo-image.qbox.me/z5kkgvSAQecHf2hv/import-WSWAuRDUZVbw1iWw.png!thumbnail)

表示第i个特征通道，通过描述器中第l层的卷积层在图片x上的表现得出。矩阵

![](https://dn-shimo-image.qbox.me/V087FQKLbVgH0ej2/import-TSUxblBhPRCYUz2E.png!thumbnail)

被定义为特征图片的内积

考虑到这个网络是一个卷积网络，要计算要对任何位置的特征i, j 做计算。因此

![](https://dn-shimo-image.qbox.me/phiQ7wwvNmEABnfC/import-eqHcMi4rpYSbbgF6.png!thumbnail)

拥有相同的一般结构，作为本地固定特征的无序的统计，是可以作为纹理描述符存在的。在实验中，Gatys等人用包含VGG中部分层的矩阵集合来衡量纹理特征，这样在图x和纹理x0之间的的代价就用下式计算：

除了纹理上的差距（texture loss），Gatys还用了一个content loss（由Mahendran& Vedaldi,2015中提出），这个content loss比较了图片在某个确定的卷积层上的输出（不计算进一步的统计数据如矩阵）

Nl是特征通道在VGG第l层的通道数，与纹理差距相比最关键的不同之处在于：内容差距保留了原图的空间位置信息，因此这种Loss函数更适合代表内容信息而不是纹理信息。类似于Gatys等人，我们将使用纹理损失（style loss）配合训练纹理合成用的生成器网络，我们使用一个纹理损失(style loss)和内容损失(content loss)的加权组合，配合训练用来做图像风格化的生成器网络。在后者的情况下，内容层不应该保留跟纹理层一样浅层的东西，只有高层的内容应该被保留。

## 3.2 生成器网络之纹理合成

我们现在讨论用于纹理合成的生成器的结构和训练过程，把生成器网络的参数记为θ，这个网络被训练成用来讲一个噪声向量z转换成一个由纹理确定的分布Z。

**网络结构：**我们实验了好几种结构用来做生成器网络g。最简单的是一串卷积，非线性激活和上采样层，从一个噪声向量z起点，终止于制造出一张图片。虽然这种类型的模型能产生合理的结果，我们发现，多尺度架构的结果具有更小的纹理损失和更好的感知质量，同时使用较少的参数以至于训练速度更快。图2包含了我们的多尺度架构的一个高层次的表示，将在之后详细介绍。纹理X0是一个tensor，shape=(M,M,3)包含了三个颜色通道，为了计算简单，假设分辨率M是2的幂，输入的噪声z是由K个随机tensor zi组成，

，我们往往用M=256 K=5，这个K个tensor都是独立同分布的，均匀分布的抽样。每个随机噪声张量是由一列卷积和非线性激活层首先处理，然后两两上采样，再作为附加通道连接在一起，最后全分辨率的张量最终用一个1x1的滤镜映射到RGB图像x上。在图2中，每一个卷积块都包含了三个卷积层，每个层都跟着一个Relu激活层，这些卷积层分别为3x3, 3x3 和1x1的感受野。步长stride为1，用循环卷积来解决边缘问题，这个很适合用于纹理。特征图谱的数量，等于filter的数量，从最小8通道到最大40通道，参数个数为65K左右，可以压缩到占用300kb内存。上采样层用了简单的最邻近插值（我们尝试过全卷积，效果不好），我们发现批量正则化层能很大的助力训练。就放在每个卷积层的后面，重要的是，还要放在连接层前面，因为沿着不同网络来的梯度需要通过批量正则化来平衡一下。**学习：**学习优化的过程用了随机梯度下降（SGD）算法，在每一次迭代时，SGD绘制一个小批量的噪声向量zk，对生成的网络进行前向评估，得到相应的图像

，利用描述器网络对其进行评估，获取纹理矩阵

![](https://dn-shimo-image.qbox.me/GAHkVW9SUTQCwtkP/import-WsIKQwRvgVIdATHH.png!thumbnail)

，最终计算Loss。（要知道

![](https://dn-shimo-image.qbox.me/4gOSRVGgwHkh72QK/import-eQMkfoWVAvmt4EEc.png!thumbnail)

）是固定的）在此之后开始反向传播，生成器的参数在反向传播时做计算，根据纹理损失上的梯度用来更新参数。LAPGAN也用了多尺度的方法，不过是分层进行训练的，然而我们的生成器是端到端的在训练。

## 3.3图像风格化

为了把这个方法应用到图像风格化上，我们做了一些改变，第一，这个生成器网络

![](https://dn-shimo-image.qbox.me/3qYACW1vaaME897d/import-erXJ41iPFN3Qfu3N.png!thumbnail)

会被修改成：输入一个噪声变量z和一个图片y的叠加，网络被训练成输出一个图像x，x在内容上靠近y，在风格上靠近x0。举个例子，y可以是某人的照片，x0可以是一张印象派名画。**网络结构：**结构跟用来做纹理合成的是一样的，唯一的重要差别就在于，噪声向量zi，i=1K，要把输入图片y做为额外的通道联结上去（对y进行下采样获取不同尺寸），我们后来发现，把K从5改成6会带来更好的结果。**学习：**学习的过程是采样噪声向量ziZ自然图像yi~Y，然后调整生成器的参数θ，使得content Loss和 style loss的和最小：

这里Z是和纹理合成时一样分布的一个噪声。Y是自然图像的经验分布，α是一个比例参数，为texture/style和content的比例。在训练中，我们发现学习令人惊讶的非常容易过拟合，而且它足以近似于自然图像y的分布，在一个非常小的图像池中。事实上，我们的结果中比较有质量的都用了很多的样例图片，我们把这样的事实归纳为：卷积结构使用本地操作，因为拥有相同的局部结构，只是图像Y、内容风格比例在变化，所以对于本地操作来说，想要匹配所有的纹理会非常的困难。尽管有这样的限制，所产生的风格化的图像通常有很好的感知质量，虽然有些风格我们的确不可能通过优化原有的方法来得到好结果。

Figure 3 　与Gatys的效果对比

# 四. 实验记录更多的技术细节

生成器网络的权重用Xavier的方式初始化，训练用Torch7实现Adam，迭代2000次，初始的学习速率为0.1，迭代1000次以后开始以每200次0.7的比例衰减。batch-size设置为16。和Gatys的论文中说的一样，纹理损失texture loss用{'relu1\_1','relu2\_1','relu3\_1','relu4\_1','relu5\_1'},VGG19模型，内容损失用{‘relu4\_2’}。完全训练好一个模型需要两个小时，用NVIDIA Tesla K40，如果只需要获得可接受的结果，则需要的时间更短，只需要很少的迭代。

**纹理合成：**我们把我们的方法和Gatys做了一些比较，我们还跟DCGAN比了，还跟还跟Portilla比了。图4呈现了这四种方法比较之后的结果，从质量上来说，我们的生成器CNN和Gatys的结果是差不多的，比另外两种方法产生的质量要好。然而生成器CNN更加的高效率（看Sect4.1），图1包括了更多的比较（生成器网络和Gatys及其他方法的对比）

Figure 4 　四种方法在纹理合成上的对比

**风格转换：**训练集，自然图像是从ImageNet ILSVRC2012的数据集中随机抽取的。至于Gatys等人得传统方法，我们发现风格化的结果是对α比例很敏感的（style/content的比例）。在测试的时候这个参数在我们的方法中不能调整，但是我们发现这个比例依旧可以通过调整输入噪声z的大小来调整（看图5）

Figure 5 　输入噪声z占比的调整

我们把我们的方法跟Gatys比较了，用了一些风格和内容图片，发现结果是非常具有可比性的。有代表性的比较，包括固定参数，是包括在图3中的，更多的补充材料，其他质量报告的结果记录在了图7中。

## 4.1 速度和内存消耗

我们把我们的方法和迭代优化的方法比较速度，通过衡量到达指定loss时各方法需要多少时间。图6展示了迭代优化的方法需要大概10秒钟去产生一个样品x，而我们的方法仅需要20ms，达成了500倍提速，这能很好的支持一些即时应用比如视频处理。产生如此显著的差别有两个原因：1.生成器网络比VGG19小太多，所以每次迭代的时候要快的多，我们的方法需要一个单独的网络来评估，通过避免反向传播，我们的方法也减少了很多内存需求，我们的方法生成256x256的图片消耗256MB， Gatys消耗1100MB。

# 五. 讨论

我们提出了一个新的深度学习方法的纹理合成和图像化的思想，显而易见的，这个方法可以用来产生一些复杂纹理及图片，用前馈网络的方式。能和使用反向传播的Gatys的方法拥有相同搞得质量。这个思路的成功在于突出了前馈网络在复杂数据生成、复杂问题解决上的合适性。这一成功的关键是使用复杂的损失函数，设计不同的前馈架构，作为“专家”评估的前馈生成器的性能。因为我们的方法获得了有很好效果的纹理合成，今后我们计划研究更好的损失函数来让纹理质量更好，实现了更令人印象深刻的结果。

# Reference

# 补充材料

生成器结构

左侧第一列是style，上方第一行是content

256x256大小训练的，但可以用来生成任意尺寸的图片
